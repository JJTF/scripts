{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZJ25PbtfwqkeuZilTnzah"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OB30YjwajNhV"},"outputs":[],"source":["# Instalar las bibliotecas necesarias\n","!pip install PyMuPDF pandas openpyxl\n","\n","import fitz  # PyMuPDF\n","import os\n","import pandas as pd\n","import re\n","\n","# Ruta a la carpeta que contiene las resoluciones directorales en Google Drive\n","folder_path = '/content/prueba'\n","vessels_path = '/content/national_vessels.xlsx'\n","\n","# Cargar el archivo de embarcaciones pesqueras\n","vessels_df = pd.read_excel(vessels_path)\n","vessels_dict = vessels_df.set_index('MATRICULA').T.to_dict('dict')\n","\n","# Lista de procedimientos TUPA y palabras clave asociadas\n","procedimientos_tupa = {\n","    \"AIF\": [\"incremento de flota\", \"construcción\", \"adquisición de embarcaciones\"],\n","    \"AMPLIACION PLAZO AIF\": [\"ampliación de plazo\", \"autorización de incremento de flota\"],\n","    \"CAMBIO TITULARIDAD AIF\": [\"cambio de titularidad\", \"incremento de flota otorgada\"],\n","    \"PERMISO EP NACIONAL\": [\"permiso de pesca\", \"embarcaciones de menor y mayor escala de bandera nacional\"],\n","    \"AMPLIACION PERMISO VIA IF\": [\"ampliación de permiso\", \"incremento de flota autorizado\"],\n","    # Añade más procedimientos y palabras clave aquí\n","    # ...\n","}\n","\n","# Función para extraer los artículos y el punto 1 de CONSIDERANDO de un PDF\n","def extract_articles_from_pdf(pdf_path):\n","    # Abrir el archivo PDF\n","    doc = fitz.open(pdf_path)\n","    articles = []\n","    inside_se_resuelve = False\n","    current_article = \"\"\n","\n","    # Variable para almacenar el punto 1 de CONSIDERANDO si se encuentra\n","    considerando_punto_1 = \"\"\n","    frase_tupa = \"\"\n","\n","    # Recorrer cada página del PDF y obtener el texto completo\n","    all_text = \"\"\n","    for page_num in range(len(doc)):\n","        page = doc.load_page(page_num)\n","        all_text += page.get_text(\"text\") + \"\\n\"\n","\n","    # Extraer el punto 1 de la sección CONSIDERANDO\n","    considerando_match = re.search(r'CONSIDERANDO:\\s*(1\\..*?)(?=\\n\\n|\\n\\d+\\.)', all_text, re.DOTALL)\n","    if considerando_match:\n","        considerando_punto_1 = considerando_match.group(1).strip()\n","        # Buscar la frase TUPA dentro del punto 1 de CONSIDERANDO\n","        match = re.search(r'en el marco del procedimiento .*? \\(TUPA\\)', considerando_punto_1, re.IGNORECASE)\n","        if match:\n","            frase_tupa = match.group(0)\n","\n","    # Procesar el texto en secciones \"SE RESUELVE\"\n","    for page_num in range(len(doc)):\n","        page = doc.load_page(page_num)\n","        text = page.get_text(\"text\")\n","        lines = text.split('\\n')\n","\n","        for line in lines:\n","            if \"SE RESUELVE:\" in line:\n","                inside_se_resuelve = True\n","            if inside_se_resuelve:\n","                if line.startswith(\"Artículo \"):\n","                    if current_article:\n","                        articles.append(current_article.strip())\n","                    current_article = line\n","                elif current_article:\n","                    if line.strip() == \"\":\n","                        articles.append(current_article.strip())\n","                        current_article = \"\"\n","                    else:\n","                        current_article += \" \" + line.strip()\n","\n","        # Añadir el último artículo al final de la página\n","        if current_article:\n","            articles.append(current_article.strip())\n","            current_article = \"\"\n","\n","    return articles, considerando_punto_1, frase_tupa\n","\n","# Función para identificar los nombres estándar basados en palabras clave\n","def identificar_nombres_estandar(articles):\n","    encontrados = set()\n","    for nombre_estandar, keywords in procedimientos_tupa.items():\n","        for article in articles:\n","            if any(keyword in article for keyword in keywords):\n","                encontrados.add(nombre_estandar)\n","                if len(encontrados) == 2:\n","                    return list(encontrados)\n","    return list(encontrados)\n","\n","# Función para identificar la embarcación pesquera y su información asociada\n","def identificar_embarcacion(articles):\n","    for article in articles:\n","        for matricula, data in vessels_dict.items():\n","            if matricula in article:\n","                return matricula, data['EMBARCACION'], data.get('ARMADOR', 'No identificado')\n","    return \"No identificado\", \"No identificado\", \"No identificado\"\n","\n","# Crear un DataFrame para almacenar los resultados\n","results = []\n","\n","# Procesar cada archivo PDF en la carpeta\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.pdf'):\n","        file_path = os.path.join(folder_path, filename)\n","        articles, considerando_punto_1, frase_tupa = extract_articles_from_pdf(file_path)\n","        nombres_estandar = identificar_nombres_estandar(articles)\n","        nombre_estandar_1 = nombres_estandar[0] if len(nombres_estandar) > 0 else \"No identificado\"\n","        nombre_estandar_2 = nombres_estandar[1] if len(nombres_estandar) > 1 else \"No identificado\"\n","        matricula, embarcacion, armador = identificar_embarcacion(articles)\n","        row = [filename, nombre_estandar_1, nombre_estandar_2, matricula, embarcacion, armador, frase_tupa, considerando_punto_1] + articles\n","        results.append(row)\n","\n","# Determinar el número máximo de artículos para definir las columnas\n","max_articles = max(len(row) for row in results) - 8\n","\n","# Crear nombres de columna dinámicamente\n","columns = ['Nombre del archivo', 'Nombre_Estandar_1', 'Nombre_Estandar_2', 'Matricula', 'Embarcacion', 'Armador', 'Frase_TUPA', 'Considerando Punto 1'] + [f'Artículo {i+1}' for i in range(max_articles)]\n","\n","# Crear el DataFrame y rellenar con None donde sea necesario\n","df = pd.DataFrame(results, columns=columns)\n","\n","# Guardar el DataFrame en un archivo Excel\n","output_path = '/content/tu.xlsx'\n","df.to_excel(output_path, index=False)\n","\n","print(f\"Los artículos extraídos se han guardado en {output_path}\")\n","\n"]}]}